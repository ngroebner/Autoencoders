{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eaxmple training CAE and VAE on MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from Autoencoders.encoders import Encoder2DConv, VAEEncoder2DConv\n",
    "from Autoencoders.decoders import Decoder2DConv\n",
    "from Autoencoders.autoencoders import Autoencoder, VAE\n",
    "from Autoencoders.losses import vae_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load FashionMNIST data and create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MNIST = datasets.MNIST('./sampledata/MNIST', download=True, train=True, transform=transforms.ToTensor())\\ndataloader = DataLoader(MNIST, batch_size=32, num_workers=2)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"MNIST = datasets.MNIST('./sampledata/MNIST', download=True, train=True, transform=transforms.ToTensor())\n",
    "dataloader = DataLoader(MNIST, batch_size=32, num_workers=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = datasets.FashionMNIST('./sampledata/FashionMNIST', download=True, train=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(traindata, batch_size=32, num_workers=2)\n",
    "\n",
    "testdata = datasets.FashionMNIST('./sampledata/FashionMNIST', download=True, train=False, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testdata, batch_size=32, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for data, _ in trainloader:\n",
    "    print(data.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the autoencoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputdims = (28,28)\n",
    "latentdims = 32\n",
    "nlayers = 2\n",
    "\n",
    "# CAE\n",
    "cae_encoder = Encoder2DConv(inputdims, latentdims, nlayers=nlayers, use_batchnorm=True)\n",
    "cae_decoder = Decoder2DConv(inputdims, latentdims, nlayers=nlayers, use_batchnorm=True)\n",
    "cae = Autoencoder(cae_encoder, cae_decoder)\n",
    "cae_loss = torch.nn.functional.mse_loss\n",
    "cae_optimizer = torch.optim.Adam(cae.parameters())\n",
    "\n",
    "#VAE\n",
    "vae_encoder = VAEEncoder2DConv(inputdims, latentdims, use_batchnorm=True)\n",
    "vae_decoder = Decoder2DConv(inputdims, latentdims, use_batchnorm=True)\n",
    "vae = VAE(vae_encoder, vae_decoder)\n",
    "#vae_loss\n",
    "vae_optimizer = torch.optim.Adam(vae.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [53440/60000 (89%)]\tLoss: 8.1924741\r"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "def train_cae(epochs):\n",
    "    cae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(trainloader):\n",
    "        cae_optimizer.zero_grad()\n",
    "        recon_x = cae(x)\n",
    "        loss = cae_loss(recon_x, x, reduction='sum')\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        cae_optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader),\n",
    "                loss.item() / len(x)),\n",
    "                end=\"\\r\", flush=True)\n",
    "\n",
    "    print('\\n====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(trainloader.dataset)))\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_cae(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 33.7637Loss: 29.769445\tRecon Loss: 20.544529\tKLD loss: 9.224916\n",
      "====> Epoch: 1 Average loss: 28.2514Loss: 28.627825\tRecon Loss: 19.285494\tKLD loss: 9.342331\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "def train_vae(epochs):\n",
    "    cae.train()\n",
    "    train_loss = 0\n",
    "    recon_loss = 0\n",
    "    kld_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(trainloader):\n",
    "        vae_optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = vae(x)\n",
    "        loss, rloss, kloss = vae_loss(recon_x, x, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        recon_loss += rloss.item()\n",
    "        kld_loss += kloss.item()\n",
    "        vae_optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tRecon Loss: {:.6f}\\tKLD loss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(x), \n",
    "                    len(trainloader.dataset),\n",
    "                    100. * batch_idx / len(trainloader),\n",
    "                    loss.item() / len(x),\n",
    "                    rloss.item() / len(x),\n",
    "                    kloss.item() / len(x)),\n",
    "                end=\"\\r\", flush=True)\n",
    "\n",
    "    print('\\n====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(trainloader.dataset)))\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    train_vae(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
